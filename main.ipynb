{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-05T08:32:09.158758Z",
     "start_time": "2023-09-05T08:30:54.656066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GGWP-Toxic-Behavior'...\r\n",
      "remote: Enumerating objects: 717, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (49/49), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (33/33), done.\u001B[K\r\n",
      "remote: Total 717 (delta 21), reused 38 (delta 15), pack-reused 668\u001B[K\r\n",
      "Receiving objects: 100% (717/717), 297.88 MiB | 4.10 MiB/s, done.\r\n",
      "Resolving deltas: 100% (224/224), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pl2599/GGWP-Toxic-Behavior.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T05:22:21.836184Z",
     "start_time": "2023-09-06T05:22:21.829932Z"
    }
   },
   "id": "462d107e8f493325"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T05:13:30.150081Z",
     "start_time": "2023-09-06T05:13:30.142708Z"
    }
   },
   "id": "fd5fd05a407efb94"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T05:13:30.150207Z",
     "start_time": "2023-09-06T05:13:30.145948Z"
    }
   },
   "id": "ea361315b61f1ac7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.read_csv('GGWP-Toxic-Behavior/data/labeled/combined.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T05:13:30.156431Z",
     "start_time": "2023-09-06T05:13:30.148236Z"
    }
   },
   "id": "c11d1f2dd7c4afb7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   index                                               text  toxic  \\\n0      0                                   real faker tweet      0   \n1      1                                              Lmfao      0   \n2      2  bruh, the best teemo player from my country is...      0   \n3      3                me and nunu tiered 3 simped for adc      0   \n4      4  yeah but i think since seraphine was released ...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>real faker tweet</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Lmfao</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>bruh, the best teemo player from my country is...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>me and nunu tiered 3 simped for adc</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>yeah but i think since seraphine was released ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T05:13:30.682716Z",
     "start_time": "2023-09-06T05:13:30.677015Z"
    }
   },
   "id": "2cf3b9847606904"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df['label'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T05:13:32.008420Z",
     "start_time": "2023-09-06T05:13:32.002683Z"
    }
   },
   "id": "9633e2fdd2ccce3f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(\n",
    "    lambda x: 'clean' if x == [0, 0, 0, 0, 0, 0] else 'toxic' if x == [1, 0, 0, 0, 0, 0] else 'severe_toxic' if x == [0,\n",
    "                                                                                                                      1,\n",
    "                                                                                                                      0,\n",
    "                                                                                                                      0,\n",
    "                                                                                                                      0,\n",
    "                                                                                                                      0] else 'obscene' if x == [\n",
    "        0, 0, 1, 0, 0, 0] else 'threat' if x == [0, 0, 0, 1, 0, 0] else 'insult' if x == [0, 0, 0, 0, 1,\n",
    "                                                                                          0] else 'identity_hate')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T05:13:32.347061Z",
     "start_time": "2023-09-06T05:13:32.341873Z"
    }
   },
   "id": "2bd84af65eef12c3"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "with open('prompts/original_prompt.txt', 'r') as f:\n",
    "    original_prompt = f.read()\n",
    "\n",
    "if not os.path.exists('outputs'):\n",
    "    os.makedirs('outputs')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T09:12:03.532300Z",
     "start_time": "2023-09-05T09:12:03.530111Z"
    }
   },
   "id": "41e8f70f05f047ed"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def sleep(seconds: int) -> None:\n",
    "    \"\"\"Sleep for a given number of seconds.\"\"\"\n",
    "    time.sleep(seconds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T09:52:32.120768Z",
     "start_time": "2023-09-05T09:52:32.117585Z"
    }
   },
   "id": "59e98472a91e861f"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def chat_model(prompt: str) -> str:\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except openai.error.APIError as e:\n",
    "        print(f\"OpenAI API returned an API Error: {e}\")\n",
    "        sleep(3)\n",
    "        return chat_model(prompt)\n",
    "    except openai.error.Timeout as e:\n",
    "        print(f\"OpenAI API request timed out: {e}\")\n",
    "        sleep(3)\n",
    "        return chat_model(prompt)\n",
    "    except openai.error.APIConnectionError as e:\n",
    "        print(f\"OpenAI API request failed to connect: {e}\")\n",
    "        sleep(3)\n",
    "        return chat_model(prompt)\n",
    "    except openai.error.RateLimitError as e:\n",
    "        print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "        sleep(5)\n",
    "        return chat_model(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T09:52:32.305969Z",
     "start_time": "2023-09-05T09:52:32.303441Z"
    }
   },
   "id": "7ee5302bed380906"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def parse_json_output(raw_text: str) -> dict:\n",
    "    \"\"\"Parse the raw text output from OpenAI API into a dictionary.\"\"\"\n",
    "    if \"```json\" in raw_text:\n",
    "        raw_text = raw_text.split(\"```json\")[1].split(\"```\")[0]\n",
    "    try:\n",
    "        return json.loads(raw_text, strict=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T09:57:26.116786Z",
     "start_time": "2023-09-05T09:57:26.112881Z"
    }
   },
   "id": "5d70632f2e6c56b3"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "if not os.path.exists('outputs/parsed'):\n",
    "    os.makedirs('outputs/parsed')\n",
    "\n",
    "if not os.path.exists('outputs/raw'):\n",
    "    os.makedirs('outputs/raw')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T10:01:55.588551Z",
     "start_time": "2023-09-05T10:01:55.583946Z"
    }
   },
   "id": "2d8b8dd512d301f8"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/raw/v1/0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m response \u001B[38;5;241m=\u001B[39m chat_model(prompt\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<message>\u001B[39m\u001B[38;5;124m'\u001B[39m, message))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# TODO: Change v1 to dynamic value\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutputs/raw/v1/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mindex\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.txt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      7\u001B[0m     f\u001B[38;5;241m.\u001B[39mwrite(response)\n\u001B[1;32m      9\u001B[0m parsed_response \u001B[38;5;241m=\u001B[39m parse_json_output(response)\n",
      "File \u001B[0;32m~/dev/miniconda3/envs/prompts-optimization-with-reasoning/lib/python3.11/site-packages/IPython/core/interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'outputs/raw/v1/0.txt'"
     ]
    }
   ],
   "source": [
    "prompt = original_prompt\n",
    "prompt_version = 'v1'\n",
    "\n",
    "for index, message in zip(df['index'], df['text']):\n",
    "    if os.path.exists(f'outputs/raw/{prompt_version}/{index}.txt') and os.path.exists(\n",
    "            f'outputs/parsed/{prompt_version}/{index}.json'):\n",
    "        continue\n",
    "\n",
    "    response = chat_model(prompt.replace('<message>', message))\n",
    "    with open(f'outputs/raw/{prompt_version}/{index}.txt', 'w') as f:\n",
    "        f.write(response)\n",
    "\n",
    "    parsed_response = parse_json_output(response)\n",
    "    with open(f'outputs/parsed/{prompt_version}/{index}.json', 'w') as f:\n",
    "        parsed_response['prompt_version'] = prompt_version\n",
    "        parsed_response['label'] = df[df['index'] == index]['label'].values[0]\n",
    "        json.dump(parsed_response, f, indent=2)\n",
    "\n",
    "    sleep(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T10:00:54.964356Z",
     "start_time": "2023-09-05T10:00:52.954795Z"
    }
   },
   "id": "6cb093ae481b04c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def accuracy_calculation(prompt_version: str):\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8e88de825791e90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Compare performance optimization via GPT-3.5 and GPT-4 and base performance of GPT-3.5 and GPT-4 without optimization\n",
    "# TODO: Save raw data, logging, add resume-ability, handle OpenAI error\n",
    "# 1. Load the prompt\n",
    "# 2. Predict the result\n",
    "# 3. Evaluate (accuracy)\n",
    "# 4. Sample the result for prompt optimization\n",
    "# 5. Get new prompt\n",
    "# 6. Loop until reach specified n or acc or stagnant\n",
    "\n",
    "# Main prompt: Replace \"<message>\"\n",
    "# Modifying prompt: Replace: \"<sample>\"\n",
    "# Each entry in <sample>\n",
    "# |- Message: <message>\n",
    "# |- Predicted class: <prediction>\n",
    "# |- Predicted reason: <reason>\n",
    "# |- Ground truth: <ground_truth>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5e2533afce12d8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
